"""
Agente A â€“ InterpretaÃ§Ã£o ClÃ­nica e OrquestraÃ§Ã£o (CORRIGIDO)
-----------------------------------------------------------
Fluxo: A â†’ B â†’ C â†’ A

Responsabilidades:
1. Receber formulÃ¡rio + texto livre
2. Normalizar dados clÃ­nicos
3. Enviar dados ao Agente B
4. Enviar resultado do B ao Agente C
5. Consolidar resposta final ao veterinÃ¡rio (CORRIGIDO)
"""

import os
from typing import Dict, Any, Optional

# =====================================================================
# CONFIGURAÃ‡ÃƒO LLM - MÃšLTIPLAS OPÃ‡Ã•ES COM FALLBACK
# =====================================================================

llm = None
LLM_DISPONIVEL = False
LLM_PROVIDER = None

# Tentar mÃºltiplos provedores em ordem de preferÃªncia
providers_to_try = []

# 1. OpenAI (melhor qualidade, requer API key)
if os.environ.get("OPENAI_API_KEY"):
    providers_to_try.append(("openai", "OpenAI GPT-3.5"))

# 2. Groq (rÃ¡pido e gratuito, requer API key)
if os.environ.get("GROQ_API_KEY"):
    providers_to_try.append(("groq", "Groq gpt-oss-120b"))

# 3. HuggingFace (gratuito, menos confiÃ¡vel)
if os.environ.get("HUGGINGFACEHUB_API_TOKEN"):
    providers_to_try.append(("huggingface", "HuggingFace"))

# Tentar cada provedor
for provider, name in providers_to_try:
    try:
        if provider == "openai":
            from langchain_openai import ChatOpenAI
            llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)
            LLM_PROVIDER = "OpenAI"
            
        elif provider == "groq":
            from langchain_groq import ChatGroq
            llm = ChatGroq(model="openai/gpt-oss-120b", temperature=0.3)
            LLM_PROVIDER = "Groq"
            
        elif provider == "huggingface":
            from langchain_huggingface import HuggingFaceEndpoint
            llm = HuggingFaceEndpoint(
                repo_id="google/flan-t5-large",
                temperature=0.2,
                max_new_tokens=512,
                huggingfacehub_api_token=os.environ.get("HUGGINGFACEHUB_API_TOKEN")
            )
            LLM_PROVIDER = "HuggingFace"
        
        # Testar se funciona
        LLM_DISPONIVEL = True
        print(f"[AGENTE A] LLM {LLM_PROVIDER} configurado")
        break
        
    except Exception as e:
        print(f"[AGENTE A] {name} nÃ£o disponÃ­vel: {e}")
        continue

if not LLM_DISPONIVEL:
    print("[AGENTE A] Nenhum LLM disponÃ­vel - usando modo texto direto")
    print("[AGENTE A] Configure: OPENAI_API_KEY, GROQ_API_KEY ou HUGGINGFACEHUB_API_TOKEN")

def gerar_explicacao_clinica(
    resultado_b: Dict[str, Any],
    resultado_c: Dict[str, Any],
    dados_clinicos: Dict[str, Any]
) -> str:
    """
    âš ï¸ FUNÃ‡ÃƒO DESATIVADA - NÃƒO USAR
    
    MOTIVO: LLM pode distorcer informaÃ§Ãµes mÃ©dicas crÃ­ticas ao "humanizar" texto.
    O Agente C Ã© o validador cientÃ­fico oficial - sua resposta jÃ¡ estÃ¡ correta
    e validada por RAG + regras IRIS. NÃ£o deve ser alterada.
    
    DECISÃƒO DE ARQUITETURA:
    - Agente C = Validador cientÃ­fico (resposta autoritativa)
    - LLM = Pode alucinar/modificar dados mÃ©dicos (RISCO)
    - SoluÃ§Ã£o = Usar resposta original de C sem modificaÃ§Ãµes
    
    Args:
        resultado_b: Resultado da inferÃªncia ontolÃ³gica
        resultado_c: Resultado da validaÃ§Ã£o (RAG + regras)
        dados_clinicos: Dados clÃ­nicos do paciente
    
    Returns:
        Texto organizado e humanizado baseado na validaÃ§Ã£o de C
    """
    
    # Pegar a mensagem de validaÃ§Ã£o do Agente C
    mensagem_c = resultado_c.get("resposta_clinica", "")
    estagio_final = resultado_c.get("estagio_final")
    valida_b = resultado_c.get("valida_b")
    
    # Se nÃ£o tem LLM, retornar direto a mensagem do C
    if not LLM_DISPONIVEL or llm is None:
        print("[AGENTE A] âš ï¸ LLM nÃ£o disponÃ­vel, usando texto direto do Agente C")
        return mensagem_c
    
    # Construir prompt para humanizar o texto
    prompt = f"""VocÃª Ã© um especialista em comunicaÃ§Ã£o veterinÃ¡ria.

Sua tarefa Ã© reescrever a avaliaÃ§Ã£o clÃ­nica a seguir em um tom claro, profissional e empÃ¡tico para um veterinÃ¡rio.

AVALIAÃ‡ÃƒO ORIGINAL DO SISTEMA DE VALIDAÃ‡ÃƒO:
{mensagem_c}

INSTRUÃ‡Ã•ES:
- Mantenha todas as informaÃ§Ãµes mÃ©dicas precisas
- FaÃ§a o texto fluir naturalmente em PORTUGUÃŠS BRASILEIRO
- Use linguagem veterinÃ¡ria profissional
- Seja conciso (3-4 sentenÃ§as)
- Mantenha a conclusÃ£o do estÃ¡gio IRIS
- RESPONDA SEMPRE EM PORTUGUÃŠS

AvaliaÃ§Ã£o reescrita em portuguÃªs:"""
    
    try:
        print(f"[AGENTE A] ğŸ§  Humanizando texto com LLM ({LLM_PROVIDER})...")
        
        # Diferentes mÃ©todos de invocaÃ§Ã£o por provider
        if LLM_PROVIDER in ["OpenAI", "Groq"]:
            from langchain_core.messages import HumanMessage
            resposta = llm.invoke([HumanMessage(content=prompt)])
            texto = resposta.content if hasattr(resposta, 'content') else str(resposta)
        else:
            resposta = llm.invoke(prompt)
            texto = resposta if isinstance(resposta, str) else str(resposta)
        
        print("[AGENTE A] âœ… Texto humanizado com sucesso")
        return texto.strip()
        
    except Exception as e:
        print(f"[AGENTE A] âš ï¸ Erro ao humanizar com LLM: {str(e)[:100]}")
        # Fallback: retornar texto do C sem modificaÃ§Ã£o
        return mensagem_c


def _gerar_explicacao_basica(
    resultado_b: Dict[str, Any],
    resultado_c: Dict[str, Any],
    dados_clinicos: Dict[str, Any]
) -> str:
    """Fallback: retorna diretamente a mensagem do Agente C"""
    return resultado_c.get("resposta_clinica", "ValidaÃ§Ã£o nÃ£o disponÃ­vel")


# =====================================================================
# HELPERS
# =====================================================================

def _to_float(value: Any) -> Optional[float]:
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        v = value.strip().replace(",", ".")
        try:
            return float(v)
        except:
            return None
    return None


def _erro(msg: str) -> Dict[str, Any]:
    return {
        "estagio_final": None,
        "mensagem": msg,
        "plano_terapeutico": [],
        "alertas": [],
        "confianca": "BAIXA"
    }


# =====================================================================
# PROCESSAMENTO DE ENTRADA
# =====================================================================

def processar_input_usuario(
    formulario: Optional[Dict[str, Any]] = None,
    texto_livre: Optional[str] = ""
) -> Dict[str, Any]:

    formulario = formulario or {}

    dados = {
        "nome": formulario.get("nome"),
        "sexo": formulario.get("sexo"),
        "raca": formulario.get("raca"),
        "creatinina": _to_float(formulario.get("creatinina")),
        "sdma": _to_float(formulario.get("sdma")),
        "idade": _to_float(formulario.get("idade")),
        "peso": _to_float(formulario.get("peso")),
        "pressao_arterial": _to_float(formulario.get("pressao_arterial") or formulario.get("pressao")),
        "upc": _to_float(formulario.get("upc")),
        "sintomas": formulario.get("sintomas", ""),
        "comorbidades": formulario.get("comorbidades", ""),
        "question": (texto_livre or "").strip()
    }

    return dados


# =====================================================================
# CONSOLIDAÃ‡ÃƒO FINAL (B + C) - CORRIGIDA
# =====================================================================

def consolidar_resultados(
    resultado_b: Dict[str, Any],
    resultado_c: Dict[str, Any],
    dados_clinicos: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    Consolida resultados de B e C respeitando os 4 casos do Agente C
    Gera explicaÃ§Ã£o clÃ­nica usando LLM
    
    Casos:
    1. B e RAG concordam â†’ confianÃ§a ALTA
    2. B nÃ£o inferiu, RAG tem info â†’ confianÃ§a MODERADA  
    3. DiscrepÃ¢ncia entre B e RAG â†’ INCONSISTÃŠNCIA (pedir nova avaliaÃ§Ã£o)
    4. Sem dados suficientes â†’ BAIXA confianÃ§a
    """
    
    dados_clinicos = dados_clinicos or {}
    
    # ğŸ”¥ PRIORIZAR campos do Agente C (ele jÃ¡ consolidou tudo)
    estagio_final = resultado_c.get("estagio_final")
    caso = resultado_c.get("caso")
    inconsistencia = resultado_c.get("inconsistencia", False)
    
    alertas = []
    
    # =====================================================================
    # CASO 3: INCONSISTÃŠNCIA/DISCREPÃ‚NCIA - ERRO CRÃTICO
    # =====================================================================
    if caso == 3 or inconsistencia:
        return {
            "estagio_final": None,
            "mensagem": resultado_c.get("resposta_clinica", "DiscrepÃ¢ncia detectada nos biomarcadores."),
            "plano_terapeutico": [],
            "alertas": [
                "âš ï¸ INCONSISTÃŠNCIA CRÃTICA: Valores de creatinina e SDMA apresentam discrepÃ¢ncia significativa.",
                "ğŸ“‹ AÃ§Ã£o requerida: Repetir exames laboratoriais antes de prosseguir com o tratamento."
            ],
            "confianca": "INVÃLIDA",
            "caso": caso
        }
    
    # =====================================================================
    # CASO 4: DADOS INSUFICIENTES
    # =====================================================================
    if caso == 4 or not estagio_final:
        return {
            "estagio_final": None,
            "mensagem": resultado_c.get(
                "resposta_clinica",
                "InformaÃ§Ãµes insuficientes para determinar o estÃ¡gio IRIS."
            ),
            "plano_terapeutico": [],
            "alertas": [
                "âš ï¸ Dados clÃ­nicos insuficientes.",
                "Por favor, forneÃ§a valores de creatinina e/ou SDMA."
            ],
            "confianca": "BAIXA",
            "caso": caso
        }
    
    # =====================================================================
    # CASOS 1 e 2: CLASSIFICAÃ‡ÃƒO VÃLIDA
    # =====================================================================
    
    # USAR DIRETAMENTE A RESPOSTA DO AGENTE C (JÃ VALIDADA)
    # O Agente C Ã© o validador cientÃ­fico - sua resposta nÃ£o deve ser alterada
    # LLM pode introduzir erros ou "alucinar" informaÃ§Ãµes mÃ©dicas
    mensagem = resultado_c.get("resposta_clinica", "")
    
    print("[AGENTE A] âœ… Usando resposta validada do Agente C (sem LLM)")
    print("[AGENTE A] ğŸ“‹ Resposta cientÃ­fica preservada para garantir precisÃ£o")
    
    # Plano terapÃªutico
    plano = resultado_c.get("tratamento_recomendado", [])
    
    # ConfianÃ§a baseada na validaÃ§Ã£o
    valida_b = resultado_c.get("valida_b")
    if valida_b is True:
        confianca = "ALTA"
        if caso == 1:
            alertas.append("âœ… InferÃªncia ontolÃ³gica validada pela literatura cientÃ­fica.")
    elif valida_b is None:
        confianca = "MODERADA"
        if caso == 2:
            alertas.append("ğŸ’¡ ClassificaÃ§Ã£o baseada na literatura (ontologia nÃ£o inferiu estÃ¡gio).")
    else:
        confianca = "MODERADA"
    
    return {
        "estagio_final": estagio_final,
        "subestagio_ap": resultado_c.get("subestagio_ap"),  # NOVO: Propagar subetÃ¡gios
        "subestagio_ht": resultado_c.get("subestagio_ht"),  # NOVO: Propagar subetÃ¡gios
        "mensagem": mensagem,
        "plano_terapeutico": plano,
        "alertas": alertas,
        "confianca": confianca,
        "caso": caso,
        
        # Metadados Ãºteis
        "valida_b": valida_b,
        "num_docs_rag": resultado_c.get("num_docs", 0),
    }


# =====================================================================
# FORMATAÃ‡ÃƒO FINAL PARA O VETERINÃRIO - CORRIGIDA
# =====================================================================

def formatar_resposta_final(resultado: Dict[str, Any], dados_clinicos: Dict[str, Any] = None) -> str:
    """
    Formata a resposta final para apresentaÃ§Ã£o ao veterinÃ¡rio
    """
    
    resposta = []
    resposta.append("ğŸ©º AvaliaÃ§Ã£o ClÃ­nica â€“ DoenÃ§a Renal CrÃ´nica Felina")
    resposta.append("=" * 70)
    
    # Adicionar informaÃ§Ãµes do paciente se disponÃ­veis
    if dados_clinicos:
        info_paciente = []
        if dados_clinicos.get("nome"):
            info_paciente.append(f"Paciente: {dados_clinicos['nome']}")
        if dados_clinicos.get("sexo"):
            sexo_desc = "Macho" if dados_clinicos['sexo'] == "M" else "FÃªmea" if dados_clinicos['sexo'] == "F" else dados_clinicos['sexo']
            info_paciente.append(f"Sexo: {sexo_desc}")
        if dados_clinicos.get("raca"):
            info_paciente.append(f"RaÃ§a: {dados_clinicos['raca']}")
        if dados_clinicos.get("idade"):
            info_paciente.append(f"Idade: {dados_clinicos['idade']} anos")
        if dados_clinicos.get("peso"):
            info_paciente.append(f"Peso: {dados_clinicos['peso']} kg")
        
        if info_paciente:
            resposta.append("")
            resposta.append("ğŸ“‹ Dados do Paciente:")
            resposta.append("-" * 70)
            resposta.append("  â€¢ " + " | ".join(info_paciente))
            resposta.append("")
    
    # ğŸ”¥ CASO 3: InconsistÃªncia - destaque especial
    if resultado.get("confianca") == "INVÃLIDA":
        resposta.append("")
        resposta.append("âš ï¸ " + "="*66)
        resposta.append("âš ï¸  ATENÃ‡ÃƒO: VALORES LABORATORIAIS INCONSISTENTES")
        resposta.append("âš ï¸ " + "="*66)
        resposta.append("")
        resposta.append(resultado.get("mensagem", ""))
        resposta.append("")
        
        if resultado.get("alertas"):
            resposta.append("ğŸ“‹ AÃ§Ãµes Recomendadas:")
            for a in resultado["alertas"]:
                resposta.append(f"   {a}")
        
        resposta.append("")
        resposta.append("=" * 70)
        return "\n".join(resposta)
    
    # EstÃ¡gio IRIS
    estagio = resultado.get("estagio_final")
    subestagio_ap = resultado.get("subestagio_ap")
    subestagio_ht = resultado.get("subestagio_ht")
    
    if estagio:
        linha_estagio = f"\nğŸ“Œ EstÃ¡gio IRIS sugerido: {estagio}"
        
        # Adicionar subetÃ¡gios se disponÃ­veis
        subetagios_str = []
        if subestagio_ap:
            ap_desc = {"AP0": "nÃ£o proteinÃºrico", "AP1": "borderline proteinÃºrico", "AP2": "proteinÃºrico"}.get(subestagio_ap, subestagio_ap)
            subetagios_str.append(f"{subestagio_ap} ({ap_desc})")
        if subestagio_ht:
            ht_desc = {"HT0": "risco mÃ­nimo", "HT1": "risco baixo", "HT2": "risco moderado", "HT3": "risco grave"}.get(subestagio_ht, subestagio_ht)
            subetagios_str.append(f"{subestagio_ht} ({ht_desc})")
        
        if subetagios_str:
            linha_estagio += f" â€” SubetÃ¡gios: {', '.join(subetagios_str)}"
        
        resposta.append(linha_estagio)
    else:
        resposta.append(f"\nâš ï¸ EstÃ¡gio IRIS: NÃƒO DETERMINADO")
    
    # FundamentaÃ§Ã£o clÃ­nica
    resposta.append("")
    resposta.append("ğŸ“„ FundamentaÃ§Ã£o:")
    resposta.append("-" * 70)
    mensagem = resultado.get("mensagem", "Nenhuma informaÃ§Ã£o disponÃ­vel")
    resposta.append(mensagem)
    
    # Alertas
    if resultado.get("alertas"):
        resposta.append("")
        resposta.append("âš ï¸  ObservaÃ§Ãµes:")
        resposta.append("-" * 70)
        for a in resultado["alertas"]:
            resposta.append(f"  â€¢ {a}")
    
    # Plano terapÃªutico
    if resultado.get("plano_terapeutico"):
        resposta.append("")
        resposta.append("ğŸ’Š RecomendaÃ§Ãµes TerapÃªuticas:")
        resposta.append("-" * 70)
        for idx, item in enumerate(resultado["plano_terapeutico"], 1):
            resposta.append(f"  {idx}. {item}")
    
    # ConfianÃ§a
    resposta.append("")
    resposta.append("-" * 70)
    confianca = resultado.get("confianca", "BAIXA")
    emoji = "ğŸŸ¢" if confianca == "ALTA" else "ğŸŸ¡" if confianca == "MODERADA" else "ğŸ”´"
    resposta.append(f"{emoji} ConfianÃ§a da anÃ¡lise: {confianca}")
    
    # Debug info (caso)
    caso = resultado.get("caso")
    if caso:
        resposta.append(f"ğŸ“Š Caso: {caso}")
    
    resposta.append("=" * 70)
    
    return "\n".join(resposta)